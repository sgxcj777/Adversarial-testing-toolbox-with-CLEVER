{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing CLEVER metric with CNN model from Keras trained with CIFAR10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import neccessary files\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Activation, Dropout\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# art library\n",
    "from art import metrics\n",
    "from art.classifiers import KerasClassifier\n",
    "from art.utils import load_dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing dataset and environment\n",
    "In this file, we will use the CIFAR10 dataset from ART.\n",
    "We will disable tensorflow 2.0's eager evaluation as ART has not been updated to support eager evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disable tensorflow 2.0 eager evaluation as it is not yet supported\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "# Read CIFAR10 dataset\n",
    "(x_train, y_train), (x_test, y_test), min_, max_ = load_dataset(str('cifar10'))\n",
    "x_train, y_train = x_train[:5000], y_train[:5000]\n",
    "x_test, y_test = x_test[:500], y_test[:500]\n",
    "im_shape = x_train[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and preparing the model\n",
    "For this example, we will use Keras Convolutional Neural Network model (CNN) without any adversarial defense training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /data/home/lamcj/.local/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "# Create Keras convolutional neural network - basic architecture from Keras examples\n",
    "# Source here: https://github.com/keras-team/keras/blob/master/examples/cifar10_cnn.py\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapping a whitebox classifier\n",
    "This creates a classifier wrapper for training of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "40/39 [==============================] - 8s 201ms/step - loss: 2.1008 - accuracy: 0.2188\n",
      "Epoch 2/10\n",
      "40/39 [==============================] - 8s 191ms/step - loss: 1.8098 - accuracy: 0.3316\n",
      "Epoch 3/10\n",
      "40/39 [==============================] - 8s 196ms/step - loss: 1.6383 - accuracy: 0.4043\n",
      "Epoch 4/10\n",
      "40/39 [==============================] - 8s 198ms/step - loss: 1.5409 - accuracy: 0.4326\n",
      "Epoch 5/10\n",
      "40/39 [==============================] - 8s 198ms/step - loss: 1.4659 - accuracy: 0.4729\n",
      "Epoch 6/10\n",
      "40/39 [==============================] - 8s 193ms/step - loss: 1.3735 - accuracy: 0.5033\n",
      "Epoch 7/10\n",
      "40/39 [==============================] - 8s 192ms/step - loss: 1.2724 - accuracy: 0.5369\n",
      "Epoch 8/10\n",
      "40/39 [==============================] - 8s 197ms/step - loss: 1.2117 - accuracy: 0.5689\n",
      "Epoch 9/10\n",
      "40/39 [==============================] - 8s 193ms/step - loss: 1.1906 - accuracy: 0.5709\n",
      "Epoch 10/10\n",
      "40/39 [==============================] - 8s 190ms/step - loss: 1.1283 - accuracy: 0.5973\n"
     ]
    }
   ],
   "source": [
    "# Create classifier wrapper\n",
    "classifier = KerasClassifier(model=model, clip_values=(min_, max_))\n",
    "#train the model\n",
    "classifier.fit(x_train, y_train, nb_epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing CLEVER score with predetermined parameters\n",
    "For computing the CLEVER score, we will use first 10 samples to calculate the CLEVER score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.955258958611852\n"
     ]
    }
   ],
   "source": [
    "#using CLEVER score with first 9 test samples\n",
    "scores = []\n",
    "for i in range(10):\n",
    "    scores.append(metrics.clever_u(classifier,x_test[i],50,10,5,1))\n",
    "\n",
    "avg_score = sum(scores)/len(scores)\n",
    "print(avg_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
