{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing CLEVER metric with CNN model from Keras trained with CIFAR10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import neccessary files\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Activation, Dropout\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# art library\n",
    "from art import metrics\n",
    "from art.classifiers import KerasClassifier\n",
    "from art.utils import load_dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing dataset and environment\n",
    "In this file, we will use the CIFAR10 dataset.\n",
    "We will disable tensorflow 2.0's eager evaluation as ART has not been updated to support eager evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disable tensorflow 2.0 eager evaluation as it is not yet supported\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "# Read CIFAR10 dataset\n",
    "(x_train, y_train), (x_test, y_test), min_, max_ = load_dataset(str('cifar10'))\n",
    "x_train, y_train = x_train[:5000], y_train[:5000]\n",
    "x_test, y_test = x_test[:500], y_test[:500]\n",
    "im_shape = x_train[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and preparing the model\n",
    "For this example, we will use Keras Convolutional Neural Network model (CNN) without any adversarial defense training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /data/home/lamcj/.local/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "# Create Keras convolutional neural network - basic architecture from Keras examples\n",
    "# Source here: https://github.com/keras-team/keras/blob/master/examples/cifar10_cnn.py\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapping a whitebox classifier\n",
    "This creates a classifier wrapper for training of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "40/39 [==============================] - 8s 201ms/step - loss: 2.1008 - accuracy: 0.2188\n",
      "Epoch 2/10\n",
      "40/39 [==============================] - 8s 191ms/step - loss: 1.8098 - accuracy: 0.3316\n",
      "Epoch 3/10\n",
      "40/39 [==============================] - 8s 196ms/step - loss: 1.6383 - accuracy: 0.4043\n",
      "Epoch 4/10\n",
      "40/39 [==============================] - 8s 198ms/step - loss: 1.5409 - accuracy: 0.4326\n",
      "Epoch 5/10\n",
      "40/39 [==============================] - 8s 198ms/step - loss: 1.4659 - accuracy: 0.4729\n",
      "Epoch 6/10\n",
      "40/39 [==============================] - 8s 193ms/step - loss: 1.3735 - accuracy: 0.5033\n",
      "Epoch 7/10\n",
      "40/39 [==============================] - 8s 192ms/step - loss: 1.2724 - accuracy: 0.5369\n",
      "Epoch 8/10\n",
      "40/39 [==============================] - 8s 197ms/step - loss: 1.2117 - accuracy: 0.5689\n",
      "Epoch 9/10\n",
      "40/39 [==============================] - 8s 193ms/step - loss: 1.1906 - accuracy: 0.5709\n",
      "Epoch 10/10\n",
      "40/39 [==============================] - 8s 190ms/step - loss: 1.1283 - accuracy: 0.5973\n"
     ]
    }
   ],
   "source": [
    "# Create classifier wrapper\n",
    "classifier = KerasClassifier(model=model, clip_values=(min_, max_))\n",
    "classifier.fit(x_train, y_train, nb_epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing of CLEVER score\n",
    "```metrics.clever_u``` is used to evaluate CLEVER score for untargetted attacks.\n",
    "```metrics.clever_t``` is used to evaluate CLEVER score for targetted attacks.\n",
    "#### Usage\n",
    "##### official documentation: <a href=\"https://adversarial-robustness-toolbox.readthedocs.io/en/latest/modules/metrics.html\">click here</a> or <a href=\"https://arxiv.org/pdf/1807.01069.pdf\"> click here</a>\n",
    "\n",
    "```metrics.clever_u(classifier, x, nb_batches, batch_size, radius, norm, c_init=1, pool_factor=10)```\n",
    "\n",
    "<ul>\n",
    "    <li><b>classifier</b> (classifier) - classifier object we wrapped above</li>\n",
    "    <li><b>x</b> (np.ndarray) - input sample (typically use x_test)</li>\n",
    "    <li><b>nb_batches</b> (int) - Number of repetitions to estimate CLEVER</li>\n",
    "    <li><b>batch_size</b> (int) - Number of random examples to sample per batch</li>\n",
    "    <li><b>radius</b> (float) - ball of radius of the maximum perturbation</li>\n",
    "    <li><b>norm</b> (int) - norm of gradient x (current support by ART: 1,2,np.inf</li>\n",
    "    <li><b>c_init</b> (float) – initialization of Weibull distribution (default=1)</li>\n",
    "    <li><b>pool_factor</b> (int) – The factor to create a pool of random samples with size pool_factor x n_s (default=10)</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predetermined parameters\n",
    "Using the authors' predetermined values, we will use the following parameters:\n",
    "- nb_batches = 50\n",
    "- batch_size = 10\n",
    "- radius = 5\n",
    "- norm = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.955258958611852\n"
     ]
    }
   ],
   "source": [
    "#using CLEVER score with first 9 test samples\n",
    "scores = []\n",
    "for i in range(9):\n",
    "    scores.append(metrics.clever_u(classifier,x_test[i],50,10,5,1))\n",
    "\n",
    "avg_score = sum(scores)/len(scores)\n",
    "print(avg_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
